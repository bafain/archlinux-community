From 40b9aca2668f443cae6bfbfa7cc5a354f1087011 Mon Sep 17 00:00:00 2001
From: Sven Woop <sven.woop@intel.com>
Date: Wed, 7 Mar 2018 11:02:01 +0000
Subject: [PATCH] AVX512 compile fix for GCC 7

---
 common/simd/vfloat16_avx512.h | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)

diff --git a/common/simd/vfloat16_avx512.h b/common/simd/vfloat16_avx512.h
index 9b7dccf714..306de62dfc 100644
--- a/common/simd/vfloat16_avx512.h
+++ b/common/simd/vfloat16_avx512.h
@@ -458,29 +458,29 @@ namespace embree
   }
 
   __forceinline vfloat16 interleave_even(const vfloat16& a, const vfloat16& b) {
-    return _mm512_castsi512_ps(_mm512_mask_shuffle_epi32(_mm512_castps_si512(a), mm512_int2mask(0xaaaa), _mm512_castps_si512(b), 0xb1));
+    return _mm512_castsi512_ps(_mm512_mask_shuffle_epi32(_mm512_castps_si512(a), mm512_int2mask(0xaaaa), _mm512_castps_si512(b), (_MM_PERM_ENUM)0xb1));
   }
 
   __forceinline vfloat16 interleave_odd(const vfloat16& a, const vfloat16& b) {
-    return _mm512_castsi512_ps(_mm512_mask_shuffle_epi32(_mm512_castps_si512(b), mm512_int2mask(0x5555), _mm512_castps_si512(a), 0xb1));
+    return _mm512_castsi512_ps(_mm512_mask_shuffle_epi32(_mm512_castps_si512(b), mm512_int2mask(0x5555), _mm512_castps_si512(a), (_MM_PERM_ENUM)0xb1));
   }
 
   __forceinline vfloat16 interleave2_even(const vfloat16& a, const vfloat16& b) {
     /* mask should be 8-bit but is 16-bit to reuse for interleave_even */
-    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(a), mm512_int2mask(0xaaaa), _mm512_castps_si512(b), 0xb1));
+    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(a), mm512_int2mask(0xaaaa), _mm512_castps_si512(b), (_MM_PERM_ENUM)0xb1));
   }
 
   __forceinline vfloat16 interleave2_odd(const vfloat16& a, const vfloat16& b) {
     /* mask should be 8-bit but is 16-bit to reuse for interleave_odd */
-    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(b), mm512_int2mask(0x5555), _mm512_castps_si512(a), 0xb1));
+    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(b), mm512_int2mask(0x5555), _mm512_castps_si512(a), (_MM_PERM_ENUM)0xb1));
   }
 
   __forceinline vfloat16 interleave4_even(const vfloat16& a, const vfloat16& b) {
-    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(a), mm512_int2mask(0xcc), _mm512_castps_si512(b), 0x4e));
+    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(a), mm512_int2mask(0xcc), _mm512_castps_si512(b), (_MM_PERM_ENUM)0x4e));
   }
 
   __forceinline vfloat16 interleave4_odd(const vfloat16& a, const vfloat16& b) {
-    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(b), mm512_int2mask(0x33), _mm512_castps_si512(a), 0x4e));
+    return _mm512_castsi512_ps(_mm512_mask_permutex_epi64(_mm512_castps_si512(b), mm512_int2mask(0x33), _mm512_castps_si512(a), (_MM_PERM_ENUM)0x4e));
   }
 
   __forceinline vfloat16 permute(vfloat16 v, __m512i index) {
